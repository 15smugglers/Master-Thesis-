# Generate a list where the i-th entry is the sequence of numbers 1,...,i
result <- lapply(1:20, function(i) seq(1, i))
# Print the result to check the output
print(result)
class(result)
class(1:10)
?lapply
result2=lapply(1:20,function(i)i^2)
result2
class(result2)
result2=lapply(1:20,k=sort(k))
result2=lapply(1:20,function(k)k=sort(k))
result2
result3=lapply(1:10,i^2)
result3=lapply(1:10,function(i)i^2)
result3
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
library(tidyverse)
library(tidyverse)
?gather
?spread
spread
spread()
install.packages("tidyverse")
install.packages("tidyverse")
spread()
library(tidyverse)
install.packages(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
install.packages("tzdb")
install.packages("knitr")
install.packages("tidyverse")
24*30
720/96
9+9+8+6+4+4+3+22+2+6+5+3+10+5
42/6
(42/6)*(12/96)
(42/6)*(96/12)
10.5*6/42
10.5/(42/96)
4/(16/96)
6*42/96 *24
6*42/96 /24
6/24
10.5*96 /42 /6
6/4 *(42/96)
(10.5 /6)*(96/42)
24*(42/96)
6712
6&12
6/12
(6/96)*(42/96)/(12/96)
96*0.21875
10.5/(6*42/96)
6*4
24*(42/96)
24*(16/96)
(6*41)/(96*96)
cumsum(c(1,2,3))
log(-2)
log(0)
ln(-2)
pnorm(0)
log(9)
log(0)
log(1)
library(ape)
install.packages("ape")
#install.packages("ape")
library(ape)
rt = rcoal(10)
plot.phylo(rt)
rt = rcoal(10)
plot.phylo(rt)
log(0)
log(999999999999)
print("Hallo")
print("Hallo")
version()
version()
install.packages("igraph")
BiocManager::install(c("RBGL","graph"))  # einmalig
library(igraph)
library(graph)
library(RBGL)
# === Eingabe: Kantenliste (parallele Kanten einfach mehrfach eintragen) ===
edges <- data.frame(
from = c(1,2,3, 1, 1, 2),
to   = c(2,3,1, 2, 3, 1)
)
# Das entspricht: 1->2, 2->3, 3->1, 1->2 (zweites Mal), 1->3, 2->1
# (Dein 2-Zyklus ist 1->2->1; "1->2->2" war vermutlich ein Vertipper.)
# === (A) Multigraph in igraph (für Multiplikitäten) ===
g_multi <- graph_from_data_frame(edges, directed = TRUE)
edge_mult <- function(u, v) {
uu <- V(g_multi)[name == as.character(u)]
vv <- V(g_multi)[name == as.character(v)]
length(E(g_multi)[ from(uu) & to(vv) ])
}
# === (B) "Einfache" gerichtete Struktur für Johnson (ohne Parallelkanten) ===
edges_unique <- unique(edges)  # Kantenart nur einmal
nodes <- sort(unique(c(edges_unique$from, edges_unique$to)))
gNEL <- graphNEL(nodes = as.character(nodes), edgemode = "directed")
for (i in seq_len(nrow(edges_unique))) {
gNEL <- addEdge(as.character(edges_unique$from[i]),
as.character(edges_unique$to[i]),
gNEL)
}
# === (C) Alle elementaren Zyklen über Knoten (Johnson) ===
cyc <- johnson.all.cycles(gNEL)  # Liste von Vektoren, z.B. c("1","2","3")
exp(-4.869927)
v <- rep(1,10)
vt <- t(v)
vt
v
v*vt
v%*%vt
1/10*v%*%vt
diag(10)-1/10*v%*%vt
v <- rep(1,2)
vt <- t(v)
1/2*v%*%vt
diag(2)-1/2*v%*%vt
diag(3)-1/2*v%*%vt
v <- rep(1,3)
vt <- t(v)
1/3*v%*%vt
diag(3)-1/2*v%*%vt
v <- rep(1,4)
vt <- t(v)
1/4*v%*%vt
diag(4)-1/2*v%*%vt
v <- rep(1,4)
vt <- t(v)
1/4*v%*%vt
diag(4)-1/4*v%*%vt
v <- rep(1,100)
vt <- t(v)
1/100*v%*%vt
diag(100)-1/100*v%*%vt
qm <- diag(100)-1/100*v%*%vt
qm
v <- rep(1,m)
m <- 100
v <- rep(1,m)
vt <- t(v)
1/m*v%*%vt
qm <- diag(m)-1/m*v%*%vt
qm
qm
qm%*%seq(1:m)
sum(qm%*%seq(1:m))
v <- c(1,2,3,1)
sum(diff(v)<=0
v <- c(1,2,3,1)
v <- c(1,2,3,1)
v
sum(diff(v)<=0)
nd <- length(v)
sum(diff(v)<=0) <(nd-1)
v <- v - mean(v)
nd <- length(v)
sum(diff(v)<=0) <(nd-1)
v
?dvnorm(
)
dmvnorm(x=c(0,0))
library(mvtnorm)
dmvnorm(x=c(0,0))
dmvnorm(x=c(0,0), mean=c(1,1))
100*65
100*65-(55*8+62*6+62*6+7:5*62+7.5*64+67*7.5+64*7.5+74*25)
100*65-(55*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25)
100*65-(55*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25)/25
(100*65-(55*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25))/25
(100*65-(65*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25))/25
(100*65-(55*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25))/25
(100*65-(75*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25))/25
(100*65-(55*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25))/25
(100*65-(55*8+62*6+67*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25))/25
(100*65-(55*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+77*25))/25
(55*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25)
(55*8+62*6+62*6+7.5*62+7.5*64+67*7.5+64*7.5+74*25)/75
load("~/Library/Mobile Documents/com~apple~CloudDocs/Studium/Dissertation MSc/Data/Finals_Runs/Modified/example-FT-a-dir/example-FT.RData")
X
betamcmc
elpd <- function(filename, burnin=1, subsample=1, num.years=T){
load(filename)
#this shouldnt be needed - if it is we need to know
if(note$DOSYNTH){if(!identical(cla,scla)) stop('wierdness encountered in elpd')}
#drop 1:(burnin-1) and allow subsampling for large output
P  <- P[seq(burnin, nrow(P), subsample), ]
PO <- PO[seq(burnin, nrow(P), subsample)]
i.na <- !is.na(P[,1])
P  <- P[i.na, ]
PO <- PO[i.na]
tau.ind <- grep("tau", colnames(P))
#compute log.lkd's
l.list <- matrix(NA, nrow(P), length(cla))
for(i in 1:nrow(l.list)){
l.list[i, ] <- unlist(
log.lkd.ser(
PO[[i]], cla, year2list(P[i, tau.ind], num.years),
years = 1:num.years,
p     = P[i, "p"],        # <-- hier der Fix (vorher P[i, 9])
model = note$model
)
)
}
ess <- effectiveSize(l.list)
loo_result  <- loo::loo(x = l.list, r_eff = ess)
waic_result <- loo::waic(l.list)
PO_bar <- PO[[1]]
for(i in 1:length(PO_bar)){ PO_bar[[i]] <- PO_bar[[i]] - PO_bar[[i]] }
for (i1 in 1:length(PO)){
for(i2 in 1:length(PO_bar)){
PO_bar[[i2]] <- PO_bar[[i2]] + PO[[i1]][[i2]]
}
}
for(i in 1:length(PO_bar)){ PO_bar[[i]] <- ((PO_bar[[i]]/i1) >= 0.5) + 0 }
l.bar <- sum(unlist(log.lkd.ser(PO_bar, cla, state$y2l, years=1:T,
p=mean(P[, "p"]), model=note$model)))
DIC <- 2*l.bar - 4*mean(P[,1])
return(list(loo_result=loo_result, waic_result=waic_result, DIC=DIC))
}
elpd <- function(filename, burnin=1, subsample=1, num.years=T){
load(filename)
#this shouldnt be needed - if it is we need to know
if(note$DOSYNTH){if(!identical(cla,scla)) stop('wierdness encountered in elpd')}
#drop 1:(burnin-1) and allow subsampling for large output
P  <- P[seq(burnin, nrow(P), subsample), ]
PO <- PO[seq(burnin, nrow(P), subsample)]
i.na <- !is.na(P[,1])
P  <- P[i.na, ]
PO <- PO[i.na]
tau.ind <- grep("tau", colnames(P))
#compute log.lkd's
l.list <- matrix(NA, nrow(P), length(cla))
for(i in 1:nrow(l.list)){
l.list[i, ] <- unlist(
log.lkd.ser(
PO[[i]], cla, year2list(P[i, tau.ind], num.years),
years = 1:num.years,
p     = P[i, "p"],        # <-- hier der Fix (vorher P[i, 9])
model = note$model
)
)
}
ess <- effectiveSize(l.list)
loo_result  <- loo::loo(x = l.list, r_eff = ess)
waic_result <- loo::waic(l.list)
PO_bar <- PO[[1]]
for(i in 1:length(PO_bar)){ PO_bar[[i]] <- PO_bar[[i]] - PO_bar[[i]] }
for (i1 in 1:length(PO)){
for(i2 in 1:length(PO_bar)){
PO_bar[[i2]] <- PO_bar[[i2]] + PO[[i1]][[i2]]
}
}
for(i in 1:length(PO_bar)){ PO_bar[[i]] <- ((PO_bar[[i]]/i1) >= 0.5) + 0 }
l.bar <- sum(unlist(log.lkd.ser(PO_bar, cla, state$y2l, years=1:T,
p=mean(P[, "p"]), model=note$model)))
DIC <- 2*l.bar - 4*mean(P[,1])
return(list(loo_result=loo_result, waic_result=waic_result, DIC=DIC))
}
path <- c("/Users/finnmaass/Downloads/Results_Thesis/PO/5 Year Block/Female/BUC/1970_1974/example-FT-a-dir/example-FT.RData"
)
elpd(path)
elpd <- function(filename, burnin=1, subsample=1, num.years=T){
load(filename)
#this shouldnt be needed - if it is we need to know
if(note$DOSYNTH){if(!identical(cla,scla)) stop('wierdness encountered in elpd')}
#drop 1:(burnin-1) and allow subsampling for large output
P  <- P[seq(burnin, nrow(P), subsample), ]
PO <- PO[seq(burnin, nrow(P), subsample)]
i.na <- !is.na(P[,1])
P  <- P[i.na, ]
PO <- PO[i.na]
tau.ind <- grep("tau", colnames(P))
#compute log.lkd's
l.list <- matrix(NA, nrow(P), length(cla))
for(i in 1:nrow(l.list)){
l.list[i, ] <- unlist(
log.lkd.ser(
PO[[i]], cla, year2list(P[i, tau.ind], num.years),
years = 1:num.years,
p     = P[i, "p"],        # <-- hier der Fix (vorher P[i, 9])
model = note$model
)
)
}
ess <- effectiveSize(l.list)
loo_result  <- loo::loo(x = l.list, r_eff = ess)
waic_result <- loo::waic(l.list)
PO_bar <- PO[[1]]
for(i in 1:length(PO_bar)){ PO_bar[[i]] <- PO_bar[[i]] - PO_bar[[i]] }
for (i1 in 1:length(PO)){
for(i2 in 1:length(PO_bar)){
PO_bar[[i2]] <- PO_bar[[i2]] + PO[[i1]][[i2]]
}
}
for(i in 1:length(PO_bar)){ PO_bar[[i]] <- ((PO_bar[[i]]/i1) >= 0.5) + 0 }
l.bar <- sum(unlist(log.lkd.ser(PO_bar, cla, state$y2l, years=1:T,
p=mean(P[, "p"]), model=note$model)))
DIC <- 2*l.bar - 4*mean(P[,1])
return(list(loo_result=loo_result, waic_result=waic_result, DIC=DIC))
}
path <- c("/Users/finnmaass/Downloads/Results_Thesis/PO/5 Year Block/Female/BUC/1970_1974/example-FT-a-dir/example-FT.RData"
)
elpd(path)
load("~/Downloads/Results_Thesis/PL/5 Year Block/Female/BUC/1970_1974/example-FT-a-dir/example-FT.RData")
############### log lik function ###
logpp <- function(dp,lambda,beta,B){
##the log lik contribution of a single list
o <- dp$o
n <- length(o)
t <- dp$time
r <- dp$rank
f <- lambda[o,t-B+1] +beta[r]
ff <- numeric(n)
for(j in 1:n){
ff[j]<- f[j]- log(sum(exp(f[j:n]))) #likelihood for one chimp
}
return(sum(ff))
}
PL_log_lik <- function(D,lambda,beta,B){
logp <- sapply(D,function(x) logpp(dp=x,lambda=lambda,beta=beta,B=B))
return(sum(logp)) #take the sum b.c. we look at the log likelihood!
}
################## check for convergence
###### log lik
l <- numeric(M/SS)
for(i in 1:(M/SS)){
l[i]<- PL_log_lik(D=D,lambda=lambdamcmc[,,i],beta=betamcmc[,i],B=B)
}
plot(l,type='l')
plot(l[-(1:1000)],type='l',ylab="log-lik")
#######sigma
plot(sigmamcmc,type='l')
############beta
plot(betamcmc[1,-c(1:1000)],type='l',ylim=c(-3,3)) #5 b.c. we just pick a random one?
########## checking the monotonicity of the betas
C <- matrix(0,(M/SS)*nd,2)
for(i in 1:nd){
C[((i-1)*(M/SS)+1):(i*(M/SS)),1]<- betamcmc[i,]
C[((i-1)*(M/SS)+1):(i*(M/SS)),2]<- i
}
boxplot(C[,1]~C[,2],ylab="values",xlab="ranks")
abline(h=0,col='red',lty="dashed")
setwd("~/Downloads/Results_Thesis/PO/Entire Data/Male/BUC")
setwd("~/Downloads/Results_Thesis/PO/Entire Data/Male/BUC")
if (exists('cl') && !is.na(cl)) {stopCluster(cl); gc()}
#rm(list=ls())
library(MASS)
library(mvtnorm)
library(mnem)    #needed for transitive.X - ed 5-4-22
library(igraph)
library(Rgraphviz)
library(graph)
library(coda)
library(lecount)
library(data.table)
#key drivers for run - at some point we will write this to a file in a new unique directory for the run
note=list()
note$RUNDIR="~/Downloads/Results_Thesis/PO/Entire Data/Male/BUC"
note$VERBOSE=FALSE
#data setup
note$B=1980
note$E=2010
if (note$B>note$E) stop('B before E')
note$doi="Gombe"
#doesnt include "Tusculum"
#note$bishopdatefile="BishopDates-25-7-22b.csv" #"BishopDates-4-11-19.csv"
note$selectlists='any'       #fraction of list time which must overlap target interval 'strict' is all, 'half' is 50% and 'any' is any
note$maxlistlength=Inf     #what list lengths allowed? NA or Inf is everything useful. Set to say 14 to knock out a few very long lists if speed an issue
note$min.lists.per.bishop=1 #for each bishop i count how many list they appear in <- if they are only in one list then i throw it out
#synth data setup
note$DOSYNTH=FALSE            #real or synthetic data?
note$srep=1                  #number of repeated copies of cla like scla<-rep(cla,srep) in synth data by setting to 2 it simulates 2 synthetic list per real list
note$true.p=0.05                #error probability was 0.1 before
note$true.q=0                 #bi-dir prob choose down
note$true.theta=0.9          #if synth then this is true theta
note$true.rho=0.925            #if syth then this is true rho
#note$true.beta=0             #if NA then simulated (and ordered) - set to zero to remove beta
note$sNF=2                   #number of features in synth data (K in notes); true K values was 2 and that gives deeper orders
# have same snF as nF for debugging (should be 6 here)
note$SYNTHTYPE='priorstate' #'poststate' #
#'poststate' means truth is last state in old file,
#'priorstate' means tau, beta and U are sampled using priors rest are true.p etc
# oldsynth means it uses synthetic data from a past run
note$TRUEINPUTFILE="./example-FT-dir/example-FT.RData" #if poststate.  Saves the output
note$OLDSYNTHINPUTFILE="./testFUN-dir/testFUN.RData" #if oldsynth
#model setup
note$NF=NA #2 before            NA sets it automatically so it sets it to 6 (2 is a lot faster and sacrfice only a little)        #number of features in U, Z so U is NB x NF x T - at least MA/2 gives all possible PO's - set to NA to get floor(MA/2)
note$constrainbeta=FALSE     #if TRUE then beta is contrained to be decreasing
note$model='lkddown'           #'lkpairwise', 'bidir', 'lkddown' or 'lkdup' or 'lkdnat' or 'prior' or 'lkmallow' at the moment - 'prior' gives the joint prior of beta,theta,rho,U
note$gender='male'            #'male', 'female
note$PhPar=list(model=note$model,
rfac=c(shape1=1,shape2=1/6,ncp=1), #prior parameters for rho
p=list(a=1,b=9),      #prior parameters for p(queue jumping), q(bidir), p(mallows)
q=list(a=1,b=1),      #p is beta prior parameters c(1,9) is default in most runs - called "subjective"
p.m=list(a=0,b=10))   #p.m is p mallows - uniform(a,b) for mallows penalty param
#MCMC drivers
note$RANDSEED=101
note$NEWRUN=TRUE             #set to FALSE if resarting old run
note$DRAW=FALSE
note$savefile='example-FT.RData'  #write MCMC samples to savefile
note$loadfile=NA             #if restarting set this to old savefile
note$LOADDIR=NA              #if restarting set this to old savedir
note$MCMC.SWEEPS=100000
note$SUBSAMPLE.INTERVAL=10   #get note$MCMC.SWEEPS/note$SUBSAMPLE.INTERVAL samples
note$DOWRITE=TRUE            #set to false if you dont want to save along the way - sensible for short runs only.
note$WRITE.SUBSAMPLE=100     #write the state to a file less frequently as this takes time for long runs
note$Usweeps=c(0,2)          #number of U-sweeps in doU (all b's per proposal) and doU2 (one b at a time) for each beta-sweep
note$UALLFRACUPD=c(0,1)      #fraction of two (fast,slow) U-updates to use
note$rho.reps=5              #number of rho-updates per sweep
note$theta.reps=5            #number of theta-updates per sweep
note$rhotheta.reps=5
note$rhotheta.wrap.reps=1
note$rhothetaU.wrap.reps=3
note$p.reps=5
note$q.reps=5
note$comment="Fixed time example (or short time anyway)"
#if the update is switched off (debugging etc) make sure init value set to something sensible
note$STARTSTATE='disordered'    #'disordered','ordered','oldstart', 'true' - 'true' only possible if synth data
note$STARTFILE="filename.RData"            #if oldstart, give the filename containing the run here - run will start from final state
note$init.beta.fac=1         #if synth & true start this multiplies init beta
note$init.U.fac=1            #if synth & true start this multiplies init U - set close to zero if testing U mcmc
#init beta is all 0 and init tau is prior sample
note$init.p=ifelse(note$STARTSTATE=='disordered',0.95,0.05)             #0.05 plausible
note$init.q=ifelse(note$STARTSTATE=='disordered',0.5,0.05)              #0.05 plausible
note$init.theta=ifelse(note$STARTSTATE=='disordered',0,0.95)          #init theta - 0.95 plausible
note$init.rho=ifelse(note$STARTSTATE=='disordered',0.1,0.9)             #init rho - 0.9 plausible
note$DOTHETA=TRUE            #do we switch on the theta-update #All the TS updates currently switched off -> need to switch on again; the TS paramter for AR(1); improvement
note$DOBETA=TRUE             #do we switch on the beta-update
note$DORHO=TRUE              #do we switch on the rho-update
note$DORHOTHETA=TRUE         #combined rho-theta update
note$DOU=TRUE                #do we switch on the U-update
note$DOP=TRUE                #P-update
note$DOQ=(note$model=='bidir')                #Q-update
note$DOTAU=FALSE              #tau-update -> only need it when we have data uncertainity
#parallel drivers - dont use this - it seems more efficient to use the cores to do multiple independent scalar runs.
#Also in current version it isnt actually any faster - seems to depend delicately on where functions defined.
#was working now v. slow
note$DOPAR=FALSE             #use parallel proc?
if (note$DOPAR) library(parallel)
note$nthread=2               #number of parallel threads - as a rule of thumb, seems not much gain above 4
#note$optimise.par.blocks=FALSE
note$split.years=1118 #c(1119,1134,1137)
#######################################################
# where are we working?
setwd(note$RUNDIR)
#old work functions including alot of legacy stuff need to be in RUNDIR
source(file="dating.R")
source(file="makedatafun.R") #had that commented out before -> appeareantly not! dont know
source(file="makesynthdatafun.R")
source(file="makeparametersfun.R")
#source(file="make_data.R")
source(file="pofun.R")
#Functions simulating priors and evalutaing log-prior densities
source(file="modelfun.R")
#Functions for output analysis
source(file="outputfun.R")
#Functions related to the MCMC
source(file="mcmcfun.R",verbose=note$VERBOSE)
#main mcmc function
source(file='mcmcPO.R')
test_path <- "/Users/finnmaass/Downloads/Results_Thesis/PO/Entire Data/Male/BUC/example-FT-dir"
save_dir  <- file.path(test_path, "plots")
if (!dir.exists(save_dir)) dir.create(save_dir, recursive = TRUE)
output <- outputanalysis(
out.dir       = test_path,
out.file      = note$savefile,
burn          = 1000,
yoi           = (note$B:note$E)-note$B+1,
pdf.file      = file.path(save_dir, "outputanalysis.pdf"),  # <— hier speichern
P.samples     = NA,
full.analysis = TRUE
)
test_path <- "/Users/finnmaass/Downloads/Results_Thesis/PO/Entire Data/Male/BUC/example-FT-dir"
save_dir  <- file.path(test_path, "plots")
if (!dir.exists(save_dir)) dir.create(save_dir, recursive = TRUE)
output <- outputanalysis(
out.dir       = test_path,
out.file      = note$savefile,
burn          = 1000,
yoi           = (note$B:note$E)-note$B+1,
pdf.file      = file.path(save_dir, "outputanalysis.pdf"),  # <— hier speichern
P.samples     = NA,
full.analysis = TRUE
)
test_path <- "/Users/finnmaass/Downloads/Results_Thesis/PO/Entire Data/Male/BUC/example-FT-a-dir"
save_dir  <- file.path(test_path, "plots")
if (!dir.exists(save_dir)) dir.create(save_dir, recursive = TRUE)
output <- outputanalysis(
out.dir       = test_path,
out.file      = note$savefile,
burn          = 1000,
yoi           = (note$B:note$E)-note$B+1,
pdf.file      = file.path(save_dir, "outputanalysis.pdf"),  # <— hier speichern
P.samples     = NA,
full.analysis = TRUE
)
